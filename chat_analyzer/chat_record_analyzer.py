import asyncio
import dataclasses
import hashlib
import logging
import re
from typing import Dict, List

from exceptions import ContactNotFoundError, TargetTableNotFoundError
from parser import AppConfig
from services import ContactDBService, ChatRecordDBService, SQLBuilder
from .analyzer_models import (
    ContactType,
    ContactRecord,
    ChatRecordCommon,
    ChatRecordCore,
    MappingCacheType,
    ProcessResultType,
    BacktrackedRecordType, AnalyzerResult, ChatRecordExtend
)

logger = logging.getLogger(__name__)

class ChatRecordAnalyzer:
    """èŠå¤©è®°å½•åˆ†æžå™¨ï¼ˆæ ¸å¿ƒä¸šåŠ¡ç±»ï¼‰"""

    def __init__(
            self,
            app_config: AppConfig  # å…¨å±€é…ç½®å®žä¾‹ï¼ˆAppConfigï¼‰
    ):
        self.app_config = app_config
        # ç¼“å­˜ï¼šæ˜ å°„å…³ç³»ï¼ˆè¡¨åâ†’è”ç³»äººä¿¡æ¯ï¼‰
        self.mapping_cache: MappingCacheType = {}
        # ç¼“å­˜ï¼šè¡¨å¤„ç†ç»“æžœï¼ˆåŽç»­æ­¥éª¤å¤ç”¨ï¼‰
        self.process_result: ProcessResultType = {}
        # ç¼“å­˜ï¼šå›žæº¯è¡¨è®°å½•ç»“æžœ,å¸¦ä¸Šä¸‹æ–‡çš„æ ¸å¿ƒè®°å½•
        self.backtracked_front_record: BacktrackedRecordType = {}
        self.backtracked_last_record: BacktrackedRecordType = {}
        self.analyzer_result: List[AnalyzerResult] = []


    async def run(self) -> List[AnalyzerResult]:
        """ç­–ç•¥æ‰§è¡Œå…¥å£ï¼ˆç»Ÿä¸€ä¸²è”æ‰€æœ‰æ­¥éª¤ï¼Œæ— éœ€é‡å†™ï¼‰"""
        # æ­¥éª¤1ï¼šèŽ·å–æ˜ å°„å…³ç³»
        self.mapping_cache = self._associate_mapping()
        # æ­¥éª¤2ï¼šèŽ·å–å¾…å¤„ç†è¡¨
        pending_tables = await self._get_pending_tables()
        # æ­¥éª¤3ï¼šå¤„ç†è¡¨æ•°æ®
        self.process_result = await self._process_tables(pending_tables)
        # æ­¥éª¤4ï¼šå›žæº¯ä¸Šä¸‹æ–‡
        self.backtracked_front_record, self.backtracked_last_record = await self._backtrack_context()
        # æ­¥éª¤5ï¼šèšåˆåˆ†æžç»“æžœ
        self.analyzer_result = self._aggregate_analyzer_results()
        # æ­¥éª¤6ï¼šç¿»è¯‘wxidç¾¤èŠåç§°
        self._replace_wxid_with_nickname()

        return self.analyzer_result



    def _associate_mapping(self) -> MappingCacheType:
        """
            æ­¥éª¤1ï¼šé¢„èŽ·å–ç›®æ ‡çš„å…¨é‡æ˜ å°„ï¼ˆremark/nick_nameâ†’usernameâ†’MD5â†’è¡¨åï¼‰
        """

        associate_mapping: MappingCacheType = {}

        # 1. ä»Žé…ç½®è¯»å–ç›®æ ‡å€¼ï¼ˆæ— éœ€åŒºåˆ†match_typeï¼Œä»…è¯»ç›®æ ‡å€¼ï¼‰
        target_value = self.app_config.stat_mode.target_contact_list  # ä»…è¯»å–ç›®æ ‡åŒ¹é…å€¼
        filter_group_chat = self.app_config.filter_config.filter_group_chat  # è¿‡æ»¤ç¾¤èŠé…ç½®

        # ========== æ‰§è¡ŒæŸ¥è¯¢å‰æ—¥å¿—ï¼ˆä»…å¿…è¦ä¿¡æ¯ï¼‰ ==========
        logger.info(f"ðŸŽ· å¼€å§‹æŸ¥è¯¢è”ç³»äººï¼šç›®æ ‡å€¼åˆ—è¡¨={target_value} | è¿‡æ»¤ç¾¤èŠ={filter_group_chat}")

        # 2. ç²¾å‡†æŸ¥è¯¢contactè¡¨ï¼ˆåŒæ—¶åŒ¹é…remarkå’Œnick_nameï¼ŒORæ¡ä»¶ï¼‰
        contact_result = ContactDBService.get_contacts(target_value, filter_group_chat)

        # æ ¡éªŒç»“æžœæ•°é‡ï¼š0æ¡æŠ¥é”™
        if len(contact_result) == 0:
            raise ContactNotFoundError(target_value)

        # æå–æŸ¥è¯¢ç»“æžœä¸­å®žé™…åŒ¹é…åˆ°çš„åç§°é›†åˆ
        matched_names = set()
        for info in contact_result:
            if info["remark"]:
                matched_names.add(info["remark"].strip())
            if info["nick_name"]:
                matched_names.add(info["nick_name"].strip())
        # ç­›é€‰é…ç½®å€¼ä¸­æœªåŒ¹é…åˆ°çš„é¡¹
        unmatched_config_values = [val for val in target_value if val.strip() not in matched_names]
        # ========== æ–°å¢žé€»è¾‘ç»“æŸ ==========

        # 3. éåŽ†æ‰€æœ‰è”ç³»äººç»“æžœï¼Œé€ä¸ªå¤„ç†å¹¶å­˜å…¥ç¼“å­˜ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šä»Žå•å…ƒç´ æ”¹ä¸ºå¾ªçŽ¯ï¼‰
        for idx, contact_info in enumerate(contact_result, 1):
            # 3.1 æå–usernameå¹¶ç”ŸæˆMD5è¡¨å
            username = contact_info["username"]
            md5_username = hashlib.md5(username.encode()).hexdigest().lower()
            target_table_name = f"Msg_{md5_username}"

            # 3.2 æž„é€ è”ç³»äººä¿¡æ¯ï¼ˆå…¼å®¹remark/nick_nameä¸ºç©ºçš„æƒ…å†µï¼‰
            contact_name = contact_info["remark"] or contact_info["nick_name"] or "æœªçŸ¥è”ç³»äºº"

            local_type = contact_info["local_type"]
            contact_type = ContactType.get_type_by_local_type_id(local_type)

            # 3.3 å­˜å…¥æ˜ å°„ç¼“å­˜ï¼ˆè¡¨åâ†’è”ç³»äººä¿¡æ¯ï¼Œè‡ªåŠ¨è¦†ç›–é‡å¤keyï¼‰
            associate_mapping[target_table_name] = ContactRecord(
                username=username,
                nickname=contact_name,
                type=contact_type,
                type_code=local_type
            )

            logger.info(
                f"ðŸŽ· ã€æ˜ å°„ç¼“å­˜-{idx}/{len(contact_result)}ã€‘"
                f"è”ç³»äººåç§°ï¼š{contact_name} | "
                f"ç±»åž‹ï¼š{contact_type}ï¼ˆåŽŸå§‹local_typeï¼š{local_type}ï¼‰ | "
                f"usernameï¼š{username} | "
                f"ç”Ÿæˆç›®æ ‡è¡¨åï¼š{target_table_name}"
            )

        # ========== æœªåŒ¹é…æ—¥å¿—ï¼ˆå¯¹é½_get_pending_tablesé£Žæ ¼ï¼‰ ==========
        if unmatched_config_values:
            for val in unmatched_config_values:
                logger.warning(f"âš ï¸ é…ç½®å€¼[{val}]æœªåœ¨è”ç³»äººè¡¨ä¸­åŒ¹é…åˆ°å¯¹åº”çš„è”ç³»äºº/ç¾¤èŠ")

        logger.info(
            f"ðŸŽ· ã€æ˜ å°„ç¼“å­˜æ±‡æ€»ã€‘é…ç½®ç›®æ ‡å€¼æ€»æ•°ï¼š{len(target_value)} | "
            f"åŒ¹é…åˆ°è”ç³»äººæ•°é‡ï¼š{len(contact_result)} | "
            f"æœªåŒ¹é…çš„é…ç½®å€¼æ•°é‡ï¼š{len(unmatched_config_values)} | "
            f"ç¼“å­˜è¡¨åæ•°é‡ï¼š{len(associate_mapping)}"
        )

        return associate_mapping


    async def _get_pending_tables(self) -> List[str]:
        """
            æ­¥éª¤2ï¼šèŽ·å–æ‰€æœ‰å¾…å¤„ç†è¡¨ï¼ˆé€‚é…å¤šè¡¨ï¼‰ï¼Œæ ¡éªŒå­˜åœ¨æ€§å¹¶è¾“å‡ºæ—¥å¿—
            è¿”å›žï¼šList[str]ï¼šå¾…å¤„ç†çš„Msgè¡¨ååˆ—è¡¨
        """

        # 1,èŽ·å–æ˜ å°„ç¼“å­˜ä¸­æ‰€æœ‰è¡¨å
        pending_table_names = list(self.mapping_cache.keys())
        total_pending = len(pending_table_names)

        # 2,è°ƒç”¨å°è£…æ–¹æ³•æ‰¹é‡æ ¡éªŒè¡¨å­˜åœ¨æ€§ï¼ˆname IN é€»è¾‘ï¼‰
        table_seq_dict = await ChatRecordDBService.check_tables_exist(pending_table_names)

        # 3,å…ˆå•ç‹¬æ”¶é›†ç¼ºå¤±çš„è¡¨ï¼ˆä¸å½±å“æŽ’åºï¼Œæ”¹åŠ¨1ï¼‰
        missing_contacts = []
        for table_name in pending_table_names:
            if table_name not in table_seq_dict:
                contact_info = self.mapping_cache[table_name]
                missing_contacts.append(
                    f"è”ç³»äºº[{contact_info.nickname}](ç±»åž‹ï¼š{contact_info.type})çš„èŠå¤©è®°å½•è¡¨[{table_name}]ç¼ºå¤±"
                )

        # 4,éåŽ†table_seq_dict.keys()ï¼ˆå·²æŽ’åºï¼‰æ”¶é›†æœ‰æ•ˆè¡¨ï¼ˆæ ¸å¿ƒæ”¹åŠ¨2ï¼‰
        valid_tables = []
        for table_name in table_seq_dict.keys():  # æ›¿æ¢åŽŸéåŽ†pending_table_names
            total_records = table_seq_dict[table_name]
            contact_info = self.mapping_cache[table_name]
            logger.info(
                f"ðŸŽ¸ è”ç³»äºº[{contact_info.nickname}]çš„ç›®æ ‡è¡¨[{table_name}]å­˜åœ¨ï¼Œè¯¥è¡¨æ€»èŠå¤©è®°å½•æ•°ï¼š{total_records}æ¡"
            )
            valid_tables.append(table_name)

        # æ—¥å¿—è®°å½•ç¼ºå¤±çš„è”ç³»äºº
        if missing_contacts:
            for missing_info in missing_contacts:
                logger.warning(f"âš ï¸ {missing_info}")

        # æ‰€æœ‰è¡¨éƒ½ç¼ºå¤±â†’æŠ›å¼‚å¸¸ï¼›éƒ¨åˆ†ç¼ºå¤±ä»…æ—¥å¿—ï¼Œè¿”å›žæœ‰æ•ˆè¡¨å
        if not valid_tables:
            raise TargetTableNotFoundError(
                target_table_name=",".join(pending_table_names),
                message="âŒ æ‰€æœ‰å¾…å¤„ç†çš„èŠå¤©è®°å½•è¡¨å‡ä¸å­˜åœ¨"
            )

        total_valid = len(valid_tables)
        total_missing = len(missing_contacts)
        logger.info(
            f"ðŸŽ¸ ã€å¾…å¤„ç†è¡¨æ ¡éªŒæ±‡æ€»ã€‘"
            f"æ€»å¾…å¤„ç†è¡¨æ•°ï¼š{total_pending} | "
            f"æœ‰æ•ˆå­˜åœ¨è¡¨æ•°ï¼š{total_valid} | "
            f"ç¼ºå¤±è¡¨æ•°ï¼š{total_missing} | "
            f"æœ€ç»ˆå¾…å¤„ç†è¡¨åˆ—è¡¨ï¼š{valid_tables}"
        )

        return valid_tables


    async def _process_tables(self, pending_tables: List[str]) -> ProcessResultType:
        """
            æ­¥éª¤3ï¼šå¤„ç†è¡¨æ•°æ®ï¼ˆåç¨‹ï¼Œæ”¯æŒå¹¶å‘ï¼‰
            å‚æ•°ï¼š
                pending_tablesï¼š_get_pending_tablesè¿”å›žçš„å¾…å¤„ç†è¡¨åˆ—è¡¨
            è¿”å›žï¼š
                Dict[str, list[ChatRecord]]ï¼š{è¡¨å: èŠå¤©è®°å½•åˆ—è¡¨}
        """

        table_chat_records: ProcessResultType = {}
        pet_phrase_config = self.app_config.pet_phrase_config
        max_concurrency = self.app_config.db_config.max_concurrency

        # 1. æž„å»ºæ—¶é—´æ¡ä»¶ï¼ˆæ‰€æœ‰è¡¨å…±ç”¨ï¼‰
        time_condition = SQLBuilder.build_time_condition(self.app_config.time_config)
        # 2. æž„å»ºå£å¤´ç¦…æ¡ä»¶+å‚æ•°ï¼ˆæ‰€æœ‰è¡¨å…±ç”¨ï¼‰
        phrase_condition, phrase_params = SQLBuilder.build_phrase_condition(pet_phrase_config)
        # 3. æž„å»ºå‘½ä¸­å…³é”®è¯åˆ—è¡¨åˆ«å
        match_keywords_sql, match_params = SQLBuilder.build_match_keywords_sql(pet_phrase_config)

        logger.info(
            f"ðŸŽ¹ æž„å»ºå…¬å…±æŸ¥è¯¢æ¡ä»¶ï¼šå¾…å¤„ç†è¡¨æ•°={len(pending_tables)} | "
            f"å£å¤´ç¦…åˆ—è¡¨={pet_phrase_config.pet_phrases}ï¼ˆåŒ¹é…ç±»åž‹={pet_phrase_config.match_type}ï¼‰ | "
            f"æ—¶é—´èŒƒå›´={time_condition} | "
            f"ä»…æŸ¥è‡ªå·±æ¶ˆæ¯={True} | "
            f"æœ€å¤§å¹¶å‘æ•°={max_concurrency}"
        )

        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrency)

        async def process_single_table(tbl_name: str) -> tuple[str, Dict[int, ChatRecordCommon]]:
            """å¤„ç†å•ä¸ªè¡¨çš„åç¨‹å‡½æ•°"""
            async with semaphore:
                # 1. è°ƒç”¨DBæœåŠ¡èŽ·å–åŽŸå§‹è®°å½•ï¼ˆå­—å…¸åˆ—è¡¨ï¼‰
                raw_records = await ChatRecordDBService.get_chat_records_by_phrase_and_time(
                    table_name=tbl_name,
                    phrase_condition=phrase_condition,
                    phrase_params=phrase_params,
                    match_keywords_sql=match_keywords_sql,
                    match_params=match_params,
                    time_condition=time_condition,
                    only_self_msg=self.app_config.stat_mode.mode_type != "target_to_self"
                )

                # 2. è½¬æ¢ä¸ºChatRecordå¯¹è±¡ï¼ˆæ ¸å¿ƒï¼šå­—å…¸â†’ç»“æž„åŒ–ç±»ï¼Œæ”¹ä¸ºlocal_idä¸ºkeyçš„dictï¼‰
                records_dict = {}  # åˆå§‹åŒ–æ”¹ä¸ºå­—å…¸ï¼Œæ›¿ä»£åˆ—è¡¨
                for raw in raw_records:
                    # åŒ¹é…ChatRecordå­—æ®µï¼Œè¡¥å……matched_phrasesï¼ˆç©ºåˆ—è¡¨å…œåº•ï¼‰
                    raw_create_time = raw["create_time"]
                    raw_matched_phrases = raw["matched_phrases"]

                    chat_record = ChatRecordCommon(
                        local_id=raw["local_id"],
                        message_content=raw["message_content"],
                        real_sender_id=raw["real_sender_id"],
                        create_time=raw_create_time,
                        matched_phrases=raw_matched_phrases.split(',') if raw_matched_phrases and raw_matched_phrases.strip() else []
                    )
                    records_dict[chat_record.local_id] = chat_record  # ä»¥local_idä¸ºkeyå­˜å…¥å­—å…¸

                logger.info(f"ðŸŽ¹ å¤„ç†è¡¨å®Œæˆï¼šè¡¨å={tbl_name} | æœ‰æ•ˆè®°å½•æ•°={len(records_dict.keys())}")
                return tbl_name, records_dict

        # å¹¶å‘å¤„ç†æ‰€æœ‰è¡¨
        tasks = [process_single_table(table_name) for table_name in pending_tables]
        results = await asyncio.gather(*tasks)

        # å°†ç»“æžœå­˜å…¥å­—å…¸
        for table_name, chat_records in results:
            table_chat_records[table_name] = chat_records

        return table_chat_records


    #region æ­¥éª¤4:å›žæº¯æ ¸å¿ƒè®°å½•çš„ä¸Šä¸‹æ–‡
    async def _backtrack_context(self) -> tuple[BacktrackedRecordType,BacktrackedRecordType]:
        """
            æ­¥éª¤4ï¼šå›žæº¯æ ¸å¿ƒè®°å½•çš„ä¸Šä¸‹æ–‡
            æŒ‰è¡¨æ‰¹é‡è¿½æº¯ä¸Šä¸‹æ–‡ï¼šåŒè¡¨çš„æ ¸å¿ƒè®°å½•ä¸€æ¬¡æŸ¥è¯¢ï¼Œå‡å°‘DBè°ƒç”¨
            :return: è¡¨åâ†’ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        total_core_records = sum(len(records) for records in self.process_result.values())
        context_front_limit = self.app_config.pet_phrase_config.context_front_limit
        context_end_limit = self.app_config.pet_phrase_config.context_end_limit

        # æ—¥å¿—åŸ‹ç‚¹ï¼ˆè´´åˆä½ çš„é£Žæ ¼ï¼‰
        logger.info(
            f"ðŸŽ» å¼€å§‹æ‰¹é‡è¿½æº¯ä¸Šä¸‹æ–‡ï¼šå¾…å¤„ç†è¡¨æ•°={len(self.process_result)} | "
            f"æ ¸å¿ƒè®°å½•æ€»æ•°={total_core_records} | "
            f"æ¯æ¡è¿½æº¯(å‰{context_front_limit},åŽ{context_end_limit})æ¡")

        # è°ƒç”¨å°è£…çš„ç§æœ‰æ–¹æ³•èŽ·å–å‰/åŽå›žæº¯IDæ˜ å°„
        backtrack_front_id_map, backtrack_last_id_map = await self._calculate_backtrack_ids()

        # åˆå§‹åŒ–å‰/åŽå›žæº¯ç»“æžœï¼ˆä¸¥æ ¼åŒ¹é…æ‹†åˆ†åŽçš„ç±»åž‹åˆ«åï¼‰
        backtrack_front_result: BacktrackedRecordType = {}
        backtrack_last_result: BacktrackedRecordType = {}

        # ========== æ ¸å¿ƒæ­¥éª¤ï¼šæŒ‰è¡¨â†’æ ¸å¿ƒIDç»´åº¦ï¼Œåˆ†åˆ«å¤„ç†å‰/åŽä¸Šä¸‹æ–‡ï¼ˆå¹¶å‘ä¼˜åŒ–ï¼‰ ==========
        max_concurrency = self.app_config.db_config.max_concurrency
        semaphore = asyncio.Semaphore(max_concurrency)

        async def process_context_for_core_id(
            tbl_name: str,
            core_id: int,
            front_id_list: List[int],
            last_id_list: List[int]
        ) -> tuple[str, int, List[ChatRecordCore], List[ChatRecordCore]]:
            """å¤„ç†å•ä¸ªæ ¸å¿ƒIDçš„å‰åŽä¸Šä¸‹æ–‡"""
            async with semaphore:
                front_ctx = await self._get_and_convert_context_records(tbl_name, front_id_list)
                last_ctx = await self._get_and_convert_context_records(tbl_name, last_id_list)
                return tbl_name, core_id, front_ctx, last_ctx

        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„ä¸Šä¸‹æ–‡æŸ¥è¯¢ä»»åŠ¡
        context_tasks = []
        for table_name in self.process_result.keys():
            # èŽ·å–å½“å‰è¡¨çš„å‰/åŽä¸Šä¸‹æ–‡IDæ˜ å°„
            table_front_id_map = backtrack_front_id_map.get(table_name, {})
            table_last_id_map = backtrack_last_id_map.get(table_name, {})

            # ä¸ºå½“å‰è¡¨çš„æ¯ä¸ªæ ¸å¿ƒIDåˆ›å»ºä»»åŠ¡
            for core_local_id in self.process_result[table_name].keys():
                front_ids = table_front_id_map.get(core_local_id, [])
                last_ids = table_last_id_map.get(core_local_id, [])
                context_tasks.append(
                    process_context_for_core_id(table_name, core_local_id, front_ids, last_ids)
                )

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä¸Šä¸‹æ–‡æŸ¥è¯¢
        if context_tasks:
            context_results = await asyncio.gather(*context_tasks)

            # åˆå§‹åŒ–æ‰€æœ‰è¡¨çš„ç»“æžœå­—å…¸
            for table_name in self.process_result.keys():
                backtrack_front_result[table_name] = {}
                backtrack_last_result[table_name] = {}

            # å°†ç»“æžœå­˜å…¥å¯¹åº”çš„è¡¨ç»“æž„
            for table_name, core_local_id, front_context, last_context in context_results:
                backtrack_front_result[table_name][core_local_id] = front_context
                backtrack_last_result[table_name][core_local_id] = last_context
        else:
            # å¦‚æžœæ²¡æœ‰ä»»åŠ¡ï¼Œåˆå§‹åŒ–ç©ºç»“æžœ
            for table_name in self.process_result.keys():
                backtrack_front_result[table_name] = {}
                backtrack_last_result[table_name] = {}

        # ========== æ–°å¢žæ—¥å¿—ï¼šç»Ÿè®¡å›žæº¯ç»“æžœå¹¶è¾“å‡º ==========
        # 4. è¾“å‡ºå„è¡¨æ˜Žç»†æ—¥å¿—ï¼ˆå¯é€‰ï¼ŒæŒ‰éœ€å¼€å¯ï¼‰
        for table_log_name in self.process_result.keys():
            front_core_count = len(backtrack_front_result.get(table_log_name, {}))
            front_ctx_count = sum(len(ctx) for ctx in backtrack_front_result.get(table_log_name, {}).values())
            last_core_count = len(backtrack_last_result.get(table_log_name, {}))
            last_ctx_count = sum(len(ctx) for ctx in backtrack_last_result.get(table_log_name, {}).values())

            logger.info(
                f"ðŸŽ» å›žæº¯è¡¨æ˜Žç»†ï¼šè¡¨å={table_log_name} | "
                f"å‰å‘ï¼šæ ¸å¿ƒIDæ•°={front_core_count} ä¸Šä¸‹æ–‡è®°å½•æ•°={front_ctx_count} | "
                f"åŽå‘ï¼šæ ¸å¿ƒIDæ•°={last_core_count} ä¸Šä¸‹æ–‡è®°å½•æ•°={last_ctx_count}"
            )

        # 1. ç»Ÿè®¡å‰å‘å›žæº¯æ•°æ®
        total_front_tables = len([t for t in backtrack_front_result.values() if t])  # éžç©ºå‰å‘è¡¨æ•°
        total_front_core_ids = sum(len(core_ids) for core_ids in backtrack_front_result.values())  # å‰å‘æ ¸å¿ƒIDæ€»æ•°
        total_front_context = sum(
            len(ctx) for core_ctx in backtrack_front_result.values() for ctx in core_ctx.values())  # å‰å‘ä¸Šä¸‹æ–‡è®°å½•æ€»æ•°

        # 2. ç»Ÿè®¡åŽå‘å›žæº¯æ•°æ®
        total_last_tables = len([t for t in backtrack_last_result.values() if t])  # éžç©ºåŽå‘è¡¨æ•°
        total_last_core_ids = sum(len(core_ids) for core_ids in backtrack_last_result.values())  # åŽå‘æ ¸å¿ƒIDæ€»æ•°
        total_last_context = sum(
            len(ctx) for core_ctx in backtrack_last_result.values() for ctx in core_ctx.values())  # åŽå‘ä¸Šä¸‹æ–‡è®°å½•æ€»æ•°

        # 3. è¾“å‡ºæ±‡æ€»æ—¥å¿—
        logger.info(
            f"ðŸŽ» ä¸Šä¸‹æ–‡å›žæº¯å®Œæˆ | "
            f"å‰å‘ï¼šéžç©ºè¡¨æ•°={total_front_tables} æ ¸å¿ƒIDæ•°={total_front_core_ids} ä¸Šä¸‹æ–‡è®°å½•æ•°={total_front_context} | "
            f"åŽå‘ï¼šéžç©ºè¡¨æ•°={total_last_tables} æ ¸å¿ƒIDæ•°={total_last_core_ids} ä¸Šä¸‹æ–‡è®°å½•æ•°={total_last_context}"
        )

        return backtrack_front_result, backtrack_last_result

    @staticmethod
    async def _get_and_convert_context_records(table_name: str, context_ids: List[int]) -> List[ChatRecordCore]:
        """
        ã€ç§æœ‰æ–¹æ³•ã€‘é€šç”¨ä¸Šä¸‹æ–‡è®°å½•æŸ¥è¯¢+è½¬æ¢é€»è¾‘
        :param table_name: è¡¨å
        :param context_ids: éœ€æŸ¥è¯¢çš„local_idåˆ—è¡¨
        :return: è½¬æ¢åŽçš„ChatRecordCoreåˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨è‹¥context_idsä¸ºç©ºï¼‰
        """
        # ç©ºIDåˆ—è¡¨ç›´æŽ¥è¿”å›žç©º
        if not context_ids:
            return []

        # è°ƒç”¨æ‰¹é‡æŸ¥è¯¢èŽ·å–åŽŸå§‹è®°å½•
        raw_records = await ChatRecordDBService.get_batch_records_by_local_ids(
            table_name=table_name,
            local_id_set=context_ids
        )

        # è½¬æ¢ä¸ºChatRecordCoreåˆ—è¡¨
        context_records = [
            ChatRecordCore(
                local_id=raw["local_id"],
                message_content=raw["message_content"],
                real_sender_id=raw["real_sender_id"],
                create_time=raw["create_time"],
            )
            for raw in raw_records
        ]

        return context_records

    async def _calculate_backtrack_ids(self) -> tuple[Dict[str, Dict[int, List[int]]], Dict[str, Dict[int, List[int]]]]:
        """
        ã€ç§æœ‰æ–¹æ³•ã€‘è®¡ç®—éœ€å›žæº¯çš„local_idï¼ˆæ‹†åˆ†å‰/åŽé™åˆ¶ï¼Œæ— å…¥å‚ï¼‰
        è§„åˆ™ï¼š
        - context_front_limitï¼šæ¯ä¸ªæ ¸å¿ƒlocal_idå‡åŽ»1åˆ°è¯¥å€¼çš„æ•°å€¼ï¼ˆå¦‚2â†’id-1ã€id-2ï¼‰
        - context_end_limitï¼šæ¯ä¸ªæ ¸å¿ƒlocal_idåŠ ä¸Š1åˆ°è¯¥å€¼çš„æ•°å€¼ï¼ˆå¦‚2â†’id+1ã€id+2ï¼‰
        :return: (backtrack_front_id_map, backtrack_last_id_map)
                 backtrack_front_id_mapï¼šè¡¨åâ†’{æ ¸å¿ƒlocal_id: å‰Næ¡çš„local_idåˆ—è¡¨}
                 backtrack_last_id_mapï¼šè¡¨åâ†’{æ ¸å¿ƒlocal_id: åŽNæ¡çš„local_idåˆ—è¡¨}
        """
        # åˆå§‹åŒ–å‰/åŽå›žæº¯IDæ˜ å°„ï¼ˆç»“æž„ï¼š{è¡¨å: {æ ¸å¿ƒlocal_id: [å›žæº¯IDåˆ—è¡¨]}}ï¼‰
        backtrack_front_id_map: Dict[str, Dict[int, List[int]]] = {}
        backtrack_last_id_map: Dict[str, Dict[int, List[int]]] = {}

        # ä»Žé…ç½®è¯»å–å‰/åŽé™åˆ¶å‚æ•°ï¼ˆæ— å…¥å‚ï¼Œå†…éƒ¨è¯»å–selfå±žæ€§ï¼‰
        context_front_limit = self.app_config.pet_phrase_config.context_front_limit
        context_end_limit = self.app_config.pet_phrase_config.context_end_limit

        # éåŽ†æ¯ä¸ªè¡¨è®¡ç®—å‰/åŽå›žæº¯ID
        for table_name, core_records_dict in self.process_result.items():
            # åˆå§‹åŒ–å½“å‰è¡¨çš„å‰/åŽå›žæº¯IDå­—å…¸ï¼ˆå†…å±‚key=æ ¸å¿ƒlocal_idï¼Œvalue=å›žæº¯IDåˆ—è¡¨ï¼‰
            table_front_ids: Dict[int, List[int]] = {}
            table_last_ids: Dict[int, List[int]] = {}

            # è·³è¿‡ç©ºè¡¨
            if not core_records_dict:
                backtrack_front_id_map[table_name] = table_front_ids
                backtrack_last_id_map[table_name] = table_last_ids
                continue

            # éåŽ†å½“å‰è¡¨çš„æ¯ä¸ªæ ¸å¿ƒlocal_id
            for core_local_id in core_records_dict.keys():
                # ========== 1. è®¡ç®—å½“å‰æ ¸å¿ƒIDçš„å‰Næ¡IDï¼ˆcontext_front_limitï¼‰ ==========
                front_id_list = []
                if context_front_limit > 0:
                    for i in range(1, context_front_limit + 1):
                        front_id = core_local_id - i
                        if front_id > 0:  # è¿‡æ»¤è´Ÿæ•°IDï¼ˆæ•°æ®åº“è‡ªå¢žä¸»é”®æ— è´Ÿæ•°ï¼‰
                            front_id_list.append(front_id)
                    front_id_list.sort()  # å‡åºæŽ’åˆ—
                table_front_ids[core_local_id] = front_id_list

                # ========== 2. è®¡ç®—å½“å‰æ ¸å¿ƒIDçš„åŽNæ¡IDï¼ˆcontext_end_limitï¼‰ ==========
                last_id_list = []
                if context_end_limit > 0:
                    for i in range(1, context_end_limit + 1):
                        last_id = core_local_id + i
                        last_id_list.append(last_id)
                    last_id_list.sort()  # å‡åºæŽ’åˆ—
                table_last_ids[core_local_id] = last_id_list

            # å­˜å…¥å½“å‰è¡¨çš„å‰/åŽå›žæº¯IDç»“æžœ
            backtrack_front_id_map[table_name] = table_front_ids
            backtrack_last_id_map[table_name] = table_last_ids

        # æ—¥å¿—è¾“å‡ºç»“æžœ
        total_front_ids = sum(len(ids) for table in backtrack_front_id_map.values() for ids in table.values())
        total_last_ids = sum(len(ids) for table in backtrack_last_id_map.values() for ids in table.values())
        logger.info(
            f"ðŸŽ» ä¸Šä¸‹æ–‡å›žæº¯local_idè®¡ç®—å®Œæˆï¼š\n"
            f"  - å‰{context_front_limit}æ¡å…±éœ€æŸ¥è¯¢{total_front_ids}æ¡ID | ç¤ºä¾‹={list(backtrack_front_id_map.values())[:1]}\n"
            f"  - åŽ{context_end_limit}æ¡å…±éœ€æŸ¥è¯¢{total_last_ids}æ¡ID | ç¤ºä¾‹={list(backtrack_last_id_map.values())[:1]}")

        return backtrack_front_id_map, backtrack_last_id_map
    #endregion


    def _aggregate_analyzer_results(self) -> List[AnalyzerResult]:
        """
            æ­¥éª¤5:å°†å„çŽ¯èŠ‚å¤„ç†ç»“æžœèšåˆä¸ºAnalyzerResultåˆ—è¡¨
            æŒ‰è”ç³»äººèšåˆçš„å®Œæ•´åˆ†æžç»“æžœåˆ—è¡¨
        """
        logger.info(f"ðŸª‰ å¼€å§‹èšåˆåˆ†æžç»“æžœ")

        analyzer_results: List[AnalyzerResult] = []

        # æŒ‰è¡¨åï¼ˆå¯¹åº”è”ç³»äººusernameï¼‰åˆ†ç»„å¤„ç†
        for username, contact in self.mapping_cache.items():
            # èŽ·å–å½“å‰è”ç³»äººçš„åŸºç¡€èŠå¤©è®°å½•
            contact_records: Dict[int, ChatRecordExtend] = {}
            if username in self.process_result:
                for local_id, common_record in self.process_result[username].items():
                    # è½¬æ¢ä¸ºæ‰©å±•è®°å½•å¹¶åˆå§‹åŒ–ä¸Šä¸‹æ–‡
                    extend_record = ChatRecordExtend(
                        **dataclasses.asdict(common_record),
                        context_front_records=[],
                        context_last_records=[]
                    )
                    contact_records[local_id] = extend_record

            # å¡«å……å‰ç½®ä¸Šä¸‹æ–‡
            if username in self.backtracked_front_record:
                for local_id, front_context in self.backtracked_front_record[username].items():
                    if local_id in contact_records:
                        contact_records[local_id].context_front_records = front_context

            # å¡«å……åŽç½®ä¸Šä¸‹æ–‡
            if username in self.backtracked_last_record:
                for local_id, last_context in self.backtracked_last_record[username].items():
                    if local_id in contact_records:
                        contact_records[local_id].context_last_records = last_context

            # æž„å»ºå½“å‰è”ç³»äººçš„åˆ†æžç»“æžœ
            analyzer_results.append(AnalyzerResult(
                contact=contact,
                chat_records=list(contact_records.values())
            ))

        logger.info(f"ðŸª‰ èšåˆå®Œæˆï¼Œå…±ç”Ÿæˆ{len(analyzer_results)}ä¸ªåˆ†æžç»“æžœå¯¹è±¡")

        return analyzer_results


    #region æ­¥éª¤6:å°†ç¾¤èŠè®°å½•ä¸­message_contenté‡Œçš„"wxid_:"å‰ç¼€æ›¿æ¢ä¸ºå¯¹åº”çš„nickname
    def _replace_wxid_with_nickname(self):
        """
        æ­¥éª¤6:å°†ç¾¤èŠè®°å½•ä¸­message_contenté‡Œçš„"wxid_:"å‰ç¼€æ›¿æ¢ä¸ºå¯¹åº”çš„nickname
        """
        # æ­¥éª¤1: æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œæ›¿æ¢æ“ä½œ
        if self.app_config.filter_config.filter_group_chat:
            logger.info("ðŸ¥ å·²è¿‡æ»¤ç¾¤èŠï¼Œä¸æ‰§è¡Œwxidæ›¿æ¢æ“ä½œ")
            return

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¾¤ç»„ç±»åž‹çš„è”ç³»äºº
        has_group = any(
            contact.type == ContactType.GROUP.value[1]
            for contact in self.mapping_cache.values()
        )
        if not has_group:
            logger.info("ðŸ¥ æ— ç¾¤ç»„ç±»åž‹è”ç³»äººï¼Œä¸æ‰§è¡Œwxidæ›¿æ¢æ“ä½œ")
            return

        # æ­¥éª¤2: èŽ·å–è”ç³»äººä¿¡æ¯å¹¶å»ºç«‹æ˜ å°„å­—å…¸
        # å‡è®¾target_valueä¸ºNoneæ—¶èŽ·å–æ‰€æœ‰è”ç³»äººï¼Œå®žé™…ä½¿ç”¨æ—¶è¯·æ ¹æ®éœ€æ±‚è°ƒæ•´
        contact_result = ContactDBService.get_contacts(None, False)
        logger.info(f"ðŸ¥ èŽ·å–åˆ°[{len(contact_result)}]æ¡è”ç³»äººä¿¡æ¯ç”¨äºŽwxidæ˜ å°„")

        # æž„å»ºusernameåˆ°nicknameçš„æ˜ å°„: ä¼˜å…ˆä½¿ç”¨remarkï¼Œå¦åˆ™ä½¿ç”¨nick_name
        username_to_nickname: Dict[str, str] = {}
        for contact in contact_result:
            username = contact.get('username')
            if not username:
                continue
            # ä¼˜å…ˆä½¿ç”¨remarkï¼Œä¸ºç©ºåˆ™ä½¿ç”¨nick_name
            nickname = contact.get('remark') or contact.get('nick_name', username)
            username_to_nickname[username] = nickname

        # æ­¥éª¤3: éåŽ†åˆ†æžç»“æžœå¹¶æ‰§è¡Œæ›¿æ¢æ“ä½œ
        for analyzer_result in self.analyzer_result:
            # å¤„ç†ç¾¤èŠè®°å½•ä¸­çš„æ‰©å±•èŠå¤©è®°å½•
            for chat_record in analyzer_result.chat_records:
                # æ›¿æ¢å½“å‰èŠå¤©è®°å½•å†…å®¹
                if self.app_config.stat_mode.mode_type == "target_to_self":
                    self._replace_wxid_content(chat_record, username_to_nickname)

                # æ›¿æ¢å‰ç½®ä¸Šä¸‹æ–‡è®°å½•
                for front_record in chat_record.context_front_records:
                    self._replace_wxid_content(front_record, username_to_nickname)

                # æ›¿æ¢åŽç½®ä¸Šä¸‹æ–‡è®°å½•
                for last_record in chat_record.context_last_records:
                    self._replace_wxid_content(last_record, username_to_nickname)

        logger.info("ðŸ¥ ç¿»è¯‘ç¾¤èŠæˆå‘˜æ˜µç§°ä»»åŠ¡å®Œæˆ")


    @staticmethod
    def _replace_wxid_content(record: ChatRecordExtend | ChatRecordCore, mapping: Dict[str, str]) -> None:
        """
        æ›¿æ¢å•ä¸ªè®°å½•ä¸­çš„message_contentå†…å®¹ï¼Œè¿”å›žæ˜¯å¦å‘ç”Ÿæ›¿æ¢
        """
        if record.real_sender_id == 1:
            return

        content = record.message_content
        # åŒ¹é…ä»¥wxid_å¼€å¤´çš„ç”¨æˆ·åå‰ç¼€ï¼ˆåŒ…å«å†’å·å’Œå¯é€‰çš„æ¢è¡Œç¬¦ï¼‰
        match = re.match(r'^(wxid_\w+):\n?', content)

        if not match:
            return

        username = match.group(1)
        nickname = mapping.get(username)
        if not nickname:
            logger.debug(f"âš ï¸ æœªæ‰¾åˆ°wxid[{username}]å¯¹åº”çš„æ˜µç§°æ˜ å°„")

        # æ‰§è¡Œæ›¿æ¢
        original_prefix = match.group(0)
        record.message_content = content.replace(original_prefix, f'{nickname}:', 1)
        logger.debug(f"ðŸ¥ wxidæ›¿æ¢å®Œæˆ: {username} -> {nickname}")
    #endregion

